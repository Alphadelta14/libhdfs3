<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Libhdfs3 by PivotalRD</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1 class="header">Libhdfs3</h1>
        <p class="header">libhdfs3 a native c/c++ hdfs client</p>

        <ul>
          <li class="download"><a class="buttons" href="https://github.com/PivotalRD/libhdfs3/zipball/master">Download ZIP</a></li>
          <li class="download"><a class="buttons" href="https://github.com/PivotalRD/libhdfs3/tarball/master">Download TAR</a></li>
          <li><a class="buttons github" href="https://github.com/PivotalRD/libhdfs3">View On GitHub</a></li>
        </ul>

        <p class="header">This project is maintained by <a class="header name" href="https://github.com/PivotalRD">PivotalRD</a></p>


      </header>
      <section>
        <h1>
<a name="libhdfs3" class="anchor" href="#libhdfs3"><span class="octicon octicon-link"></span></a>libhdfs3</h1>

<p><strong>A Native C/C++ HDFS Client</strong></p>

<h2>
<a name="description" class="anchor" href="#description"><span class="octicon octicon-link"></span></a>Description</h2>

<p>The Hadoop Distributed File System (HDFS) is a distributed file system designed to run on commodity hardware. HDFS is highly fault-tolerant and is designed to be deployed on low-cost hardware. HDFS provides high throughput access to application data and is suitable for applications that have large data sets.</p>

<p>HDFS is implemented in JAVA language and additionally provides a JNI based C language library <em>libhdfs</em>. To use libhdfs, users must deploy the HDFS jars on every machine. This adds operational complexity for non-Java clients that just want to integrate with HDFS.</p>

<p><strong>Libhdfs3</strong>, which is designed as an alternative implementation of libhdfs, is implemented based on native Hadoop RPC protocol and HDFS data transfer protocol. It get rid of the drawback of JNI, has lightweight, small memory footprint code base, and is easy to use and deployed.</p>

<p>Libhdfs3 is developed by <a href="http://www.pivotal.io/">Pivotal</a> and first used in HAWQ project which is shipped in <a href="http://www.pivotal.io/big-data/pivotal-hd">Pivotal HD</a>.</p>

<h1></h1>

<h2>
<a name="installation" class="anchor" href="#installation"><span class="octicon octicon-link"></span></a>Installation</h2>

<h3>
<a name="requirement" class="anchor" href="#requirement"><span class="octicon octicon-link"></span></a>Requirement</h3>

<p>To build libhdfs3, the following libraries are needed.</p>

<pre><code>cmake (2.8+)                    http://www.cmake.org/
boost (tested on 1.53+)         http://www.boost.org/
google protobuf                 http://code.google.com/p/protobuf/
libxml2                         http://www.xmlsoft.org/
kerberos                        http://web.mit.edu/kerberos/
libuuid                         http://sourceforge.net/projects/libuuid/
libgsasl                        http://www.gnu.org/software/gsasl/
</code></pre>

<p>To run tests, the following libraries are needed.</p>

<pre><code>gtest (tested on 1.7.0)         already integrated in the source code
gmock (tested on 1.7.0)         already integrated in the source code
</code></pre>

<p>To run code coverage test, the following tools are needed.</p>

<pre><code>gcov (included in gcc distribution)
lcov (tested on 1.9)            http://ltp.sourceforge.net/coverage/lcov.php
</code></pre>

<h3>
<a name="configuration" class="anchor" href="#configuration"><span class="octicon octicon-link"></span></a>Configuration</h3>

<p>Assume libhdfs3 home directory is LIBHDFS3_HOME.</p>

<pre><code>cd LIBHDFS3_HOME
mkdir build
cd build
../bootstrap
</code></pre>

<p>Environment variable CC and CXX can be used to setup the compiler.
Script "bootstrap" is basically a wrapper of cmake command, user can use cmake directly to tune the configuration. </p>

<p>Run command "../bootstrap --help" for more configuration. </p>

<h3>
<a name="build" class="anchor" href="#build"><span class="octicon octicon-link"></span></a>Build</h3>

<p>Run command to build</p>

<pre><code>make
</code></pre>

<p>To build concurrently, rum make with -j option.</p>

<pre><code>make -j8
</code></pre>

<h3>
<a name="test" class="anchor" href="#test"><span class="octicon octicon-link"></span></a>Test</h3>

<p>To do unit test, run command</p>

<pre><code>make unittest
</code></pre>

<p>To do function test, first start HDFS, and create the function test configure file at LIBHDFS3_HOME/test/data/function-test.xml, an example can be found at LIBHDFS3_HOME/test/data/function-test.xml.example. And run command.</p>

<pre><code>make functiontest
</code></pre>

<p>To show code coverage result, run command. Code coverage result can be found at BUILD_DIR/CodeCoverageReport/index.html</p>

<pre><code>make ShowCoverage
</code></pre>

<h3>
<a name="install" class="anchor" href="#install"><span class="octicon octicon-link"></span></a>Install</h3>

<p>To install libhdfs3, run command</p>

<pre><code>make install
</code></pre>
      </section>
      <footer>
        <p><small>Hosted on <a href="http://pages.github.com">GitHub Pages</a> using the Dinky theme</small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
		
  </body>
</html>
